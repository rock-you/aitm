==== Introducing operations management

===== Defining operations

.Network operations center footnote:[_Image credit https://www.flickr.com/photos/cogdog/537486932/, downloaded 2016-11-20, commercial use permitted_]
image::images/2.06-NOC.jpg[network operations center, 400, 200, float="right"]

What do we mean by operations? Operations management is a broad topic in management theory, with whole programs dedicated to it. Companies frequently hire Chief Operations Officers to run the organization. We started to cover operations management in chapter 5, as we examined the topic of “work management” - in traditional operations management, the question of work and who is doing it is critical. However, for the digital professional, “operations” tends to have a more technical meaning, being focused on the immediate questions of systems integrity, availability and performance, and feedback from the user community (i.e., the service or help desk).

Operations often can mean, “everything but development” in a digital context. When merged with Development into “DevOps,” one gets Product Management. Recall our discussion of xref:design[product design] -- the entire experience is part of the product. This applies to both those consuming it as well as running it.

IMPORTANT: In a digitally transformed enterprise, Operations is part of the Product.

A duty-oriented, physical presence in the service of executing particular tasks is an unchanging aspect of operational responsibility. The tasks may support broader goals and strategies, and need to be systematically discharged.

What do we mean by this?

Consider the following various examples of “operations” in an IT context. Some are relevant to a “xref:amazon-productization[two pizza product team]” scenario, some might be more applicable to larger environments:

* Systems operators sitting in 24x7 operations centers, monitoring system status and responding to alerts.
* Help desk representatives answering phone calls from users requiring support. They may be calling because a system or service they need is malfunctioning. They may also be calling because they do not understand how to use the system for the value experience they have been led to expect from it.
* Field technicians physically dispatched to a campus or remote site to evaluate and if necessary update or fix IT hardware and/or software (install a new PC, fix a printer, service a cell tower antenna).
* Developers and engineers serving "on call" on a rotating basis to respond to systems outages referred to them by the operations center.
* Data center staff performing routine work, such as installing hardware, granting access, or running or testing backups. Such routine work may be scheduled, or it may be on request (e.g. ticketed).
* Security personnel ensuring security protocols are followed, e.g. access controls.

As above, the primary thing that operations does NOT do is develop new systems functionality. However, new functionality usually has operational impacts. In manufacturing and other traditional industries, product development was a minority of work, while operations was where the bulk of work happened. Yet when an operational task involving information becomes well defined and repetitive, it can be automated with a computer. This continuous cycle of innovation and commoditization has driven closer and closer ties between “development” and “operations.” This cycle also has driven confusion around exactly what is meant by “operations.” In many organizations, there is an “Infrastructure and Operations” function. Pay close attention to the naming. A matrix may help, because we have two dimensions to consider here.

.Application, infrastructure, development, operations.
[cols="h,2*", options="header"]
|====
||Development phase
|Operations phase
|Application layer
|Application developers. Handle demand, proactive and reactive, from product and operations.
|Help desk. Application support and maintenance (provisioning, fixes not requiring software development).
|Infrastructure layer
|Engineering team. Infrastructure platform engineering and development (design and build typically of externally sourced products).
|Operations center. Operational support, including monitoring system status. May monitor both infrastructure and application layers.
|====

Notice that we distinguish carefully between the application and infrastructure layers. Review our xref:what-is-IT-infrastructure[definitions]:

* applications are consumed by people who are NOT primarily concerned with IT
* infrastructure IS consumed by people who ARE primarily concerned with IT

Infrastructure services and/or products, as we discussed in Chapter 2, need to be designed and developed before they are operated, just like applications. This may all seem obvious, but there is an industry tendency to lump three of the four cells in the table into the "Infrastructure and Operations" (or "I&O") function, when in fact each represents a distinct set of concerns.

anchor:ops-day-in-life[]

===== A day in the life


Limoncelli, Strata, and Hogan, in their excellent _Cloud Systems Administration_, emphasize the role of the "oncall" and "onduty" staff in the service of operations <<Limoncelli2014>>. _Oncall_ staff have a primary responsibility of emergency response, and the term oncall refers to their continuous availability, even if they are not otherwise working (e.g., they are expected to pick up phone calls and alerts at home and dial into emergency communications channels). _Onduty_ staff are responsible for responding to non-critical incidents and maintaining current operations.

 Emergency vs non-emergency - it's all a matter of expectations
 The classic processes (Incident, Problem, Change) - also Issue, Defect, Request

At the end of the day, we need to remember that operational work is just one form of work. In the classic model, developers built systems and "threw them over the wall" to operations. Each side had specialized processes and technology supporting their particular concerns.

Now, companies undergoing digital transformation are experimenting with many different models; as we will see in Part III, up to and including the complete merging of Development and Operations-oriented skills under common product management.


 move next section elsewhere?
===== Environments and the fierce god of "Production"

[quote, unknown]
“Don’t mess with that server! It’s … Production!!!”

“Production” is a term that new IT recruits rapidly learn has forbidding connotations. To be “in production” means that the broader enterprise value stream is directly dependent on that asset. Breakage or mishandling will result in questions and concerns from powerful forces. Be Very Scared.

How do things get to be “in production”? What do we mean by that?

First, let’s get back to our fundamental principle that there is an IT system delivering some "moment of truth" to someone. This system can be of any scale, but fundamentally we are able to conceive of it having a “state.” (See http::/url[State, Configuration, and Discovery].)

When we want to change the behavior of this system, we are cautious. We reproduce the system at varying levels of fidelity and experiment with potential changes. This is called development.

When we start to gain confidence in our experiments, we increase the fidelity and also start to communicate more widely that we are contemplating a change to the state of the system. We may increase the fidelity along a set of traditional names: 

* Development
* Testing
* QA
* Integration
* Performance Testing

The final state, where value is realized, is “Production.”

image::images/2.06-environments.png[]

There is nothing sacred about the environments listed above. You will see many variations, especially at scale.

The idea that one sequentially moves (”promotes”) new system functionality through a series of states to gain confidence before finally changing the state of the production system is historically well established. However, the production state is notoriously difficult to reproduce fully, especially in highly distributed environments. While infrastructure as code has simplified the problem, lower environments simply can't match production completely in all its complexity, especially interfaced interactions with other systems or when large, expensive pools of capacity are involved.. Therefore there is always risk in changing the state of the production system. Mitigating strategies include:

* Extensive automated test harnesses that can quickly determine if system behavior has been unfavorably altered.
* Elaborating lower environments with strategies such as service virtualization to make them appear more like production.
* Hardening services against their own failure in production, or the failure of services on which they depend.
* Reducing the size (and therefore complexity and risk) of changes to production (a key DevOps strategy).
* Ensuring that changes to the production system can be easily and automatically reversed.
* Using policy-aware infrastructure management tools.

Another important development in environmental approaches is A/B testing. In this approach, the “production” environment is segregated into two or more discrete states, with different features or behaviors exposed to users in order to assess their reactions (see sidebar).

===== Do we need environments at all?
The author has heard it recommended that the term “environment” be eliminated, as it tends to result in turf wars and empire building, and potentially the waste of fixed assets (see chapter 8). Performance environments are particularly in question.

Instead, in a dynamic infrastructure environment (private or public), one simply defines the kind of test one wants to perform and provisions that capacity on-demand.

****
*Testing in Production?*

It used to be that the concept of “testing in production” was frowned upon. Now, with these mitigating strategies, and the recognition that complex systems cannot ever be fully reproduced, there is more tolerance for the idea.

But with older systems that may lack automated testing, incremental deployment, or easy rollback, it is strongly recommended to retain existing promotion strategies, as these are battle-tested and known to reduce risk. Often, their cycle time can be decreased.
****

===== “Development is production”

On the flip side, development systems must never be treated casually.

* The development pipeline itself (Chapter 3, figure X) represents a significant operational commitment.
* The failure of a source code repository, if not backed up, could wipe out a company (see the Code Spaces sidebar in Chapter 2).
* The failure of a build server or package repository could be almost as bad.
* In the digital economy, dozens or hundreds of developers out of work represents a severe operational and financial setback, even if the nominal “production” systems continue to function.

It’s therefore important to treat “development” platforms with the same care as production systems. This requires nuanced approaches: with infrastructure as code, particular virtual machines or containers may represent experiments, expected to fail often and be quickly rebuilt. No need for burdensome change processes when VM base images and containers are being set up and torn down hundreds of times each day!

But the platforms supporting the instantiation and teardown of those VMs are production platforms, supporting the business of new systems development.
