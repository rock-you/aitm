
anchor:frameworks[]

==== Process frameworks
ifdef::collaborator-draft[]

****
*Collaborative*

_Status: This section is in first draft as of 9 Jun 2016. Comments appreciated._

include::../../../collab-links.adoc[]

****

endif::collaborator-draft[]

We will now turn to a critical examination of the IT management frameworks. While there is much of value in them, there are many places where they may lead you into the "defined process" trap, and they may not provide enough support for the alternative approach of empirical process control.


===== Defining frameworks

NOTE: There are other usages of the term "framework," especially in terms of software frameworks. Process and management frameworks are non-technical.

So, what is a "framework?"

The term "framework," in the context of business process, is used for comprehensive and systematic representations of a major business area's activities. In general, an industry framework is a structured artifact that seeks to articulate a professional consensus regarding a domain of practice. The intent is usually that the guidance be mutually exclusive and collectively exhaustive within the domain, so that persons knowledgeable in the framework have a broad understanding of domain concerns.

The first goal of any framework, for a given conceptual space, is to provide a "map" of its components and their relationships. Doing this serves a variety of goals:

* Develop and support professional consensus on the business area
* Support training and orientation of professionals new to the area (or its finer points)
* Support governance and control activities related to the area (more on this in Chapter 10)

===== An overview of the major frameworks

Many frameworks have emerged in the IT space, with broader and narrower domains of concern. Some are owned by non-profit standards bodies; others are commercial. We will focus on five in this book. In roughly chronological order, they are:

* CMMI (Capability Maturity Model-Integrated)
* ITIL (originally the Information Technology Infrastructure Library)
* PMBOK (The Project Management Body of Knowledge)
* COBIT (aka Control Objectives for Information Technology)
* TOGAF (The Open Group Architecture Framework)

A 6th framework, IT4IT, will be discussed in Chapter 12.

anchor:CMMI[CMMI]

====== CMMI
The Capability Maturity Model was originally published by Watts Humphrey in 1989 in the book _Managing the Software Process_ <<Humphrey1989>>.

The CMM was later taken on by the Software Engineering Institute at Carnegie-Mellon University, and is now managed by the CMMI Institute, which was acquired in 2016 by  ISACA.

The CMM has had considerable influence on software development and IT management more generally. It popularized the idea that process management tends to evolve in the same way across organizations, following a "staged" model:

Stage 1: Initial

Stage 2: Repeatable

Stage 3: Defined

Stage 4: Managed

Stage 5: Optimizing

(These are Humphrey's original levels. There are some differences with the current CMMI, but the concept is the same.)

These ideas can be seen reflected in later guidance such as COBIT and ITIL.

Within this overall framework of maturation, CMMI currently calls for 22 process areas:

* Causal Analysis and Resolution (CAR)
* Configuration Management (CM)
* Decision Analysis and Resolution (DAR)
* Integrated Project Management (IPM)
* Measurement and Analysis (MA)
* Organizational Process Definition (OPD)
* Organizational Process Focus (OPF)
* Organizational Performance Management (OPM)
* Organizational Process Performance (OPP)
* Organizational Training (OT)
* Product Integration (PI)
* Project Monitoring and Control (PMC)
* Project Planning (PP)
* Process and Product Quality Assurance (PPQA)
* Quantitative Project Management (QPM)
* Requirements Development (RD)
* Requirements Management (REQM)
* Risk Management (RSKM)
* Supplier Agreement Management (SAM)
* Technical Solution (TS)
* Validation (VAL)
* Verification (VER)

CMMI for a time was a critical requirement for obtaining US Government contracts, especially from the Department of Defense. As a result, outsourcing firms devoted significant effort and resources to becoming "Level 5" certified.


anchor:ITIL[ITIL]

====== ITIL
About the same time as the CMM's initial creation and transition to the Software Engineering Institute, the Central Computer and Telecommunications Agency of the United Kingdom recognized that IT practices were becoming fragmented. In response, a multi-volume set of guidance known as the IT Infrastructure Library was created. A 2nd edition consolidated and updated this guidance, and achieved worldwide acceptance as a de facto standard for IT management. The term "service" was inserted, i.e. "IT Service Management" but the distinction between the ITSM term and simple "IT Management" has always been somewhat unclear.

Due to the particular structure of UK government publications, ITIL has never covered project management or the SDLC per se, or analysis, architecture and design.

ITIL is currently published via the Axelos commercial joint venture between the UK government and Capita Group. It is now in its 4th major edition (2011). While often considered an “operational” framework, ITIL spans the lifecycle of IT services and systems; the current volumes reflect a lifecycle:

* Service Strategy
* Service Design
* Service Transition
* Service Operations
* Continual Service Improvement

Within these volumes, ITIL defines a number of activities, functions, and what it calls processes (more on this below). These definitions have helped stabilize industry practice and provided a basis for industry training and certification of individuals.

ITIL's processes include:

[cols="2,6", options="header"]
|====
|ITIL Stage|Processes
|Service Strategy
|Strategy Management for IT Services +
Service Portfolio Management +
Demand Management +
Financial Management for IT Services +
Business Relationships Management +
|Service Design
|Design Coordination +
Service Catalogue Management +
Service Level Management +
Risk Management +
Capacity Management +
Availability Management +
IT Service Continuity Management +
Information Security Management +
Compliance Management +
Architecture Management +
Supplier Management +
|Service Transition
|Change Management
Change Evaluation +
Project Management (Transition Planning and Support) +
Application Development +
Release and Deployment Management +
Service Validation and Testing +
Service Asset and Configuration Management +
Knowledge Management +
|Service Operation
|Event Management +
Incident Management +
Request Fulfillment +
Access Management +
Problem Management +
IT Operations Control +
Facilities Management +
Application Management +
Technical Management +
|Continual Service Improvement
|Service Review +
Process Evaluation +
Definition of CSI Initiatives +
Monitoring of CSI Initiatives +
|====

====== PMBOK
The Project Management Body of Knowledge is a publication of the Project Management Institute. It represents the codification of formal project management knowledge. There is a comparable Axelos publication, Prince2, not covered here. PMBOK was covered in xref:PMBOK[Chapter 8].


anchor:COBIT[COBIT]

====== COBIT
COBIT (originally the Control Objectives for Information Technology) is a set of guidance from ISACA (originally the IS Audit and Control Association). It has a broader scope than ITIL, as it includes architecture and project management. Where ITIL contains lengthy and detailed narrative, COBIT is more terse and structured.

We will discuss the concepts of IT governance and controls in the next section, and therefore at this point in the reading are not completely ready to evaluate COBIT in terms of its initial objectives. (In COBIT terms, processes are just one of various "xref:enablers[enablers]" that can serve as controls for enterprise risk.) However, COBIT is widely used as a reference for understanding IT organizational processes and activities, and is discussed in that sense in this chapter.

The following processes are suggested by COBIT for IT management and goverance. (_Governance_, the "EDM" processes, is very clearly distinguished from _management_ in COBIT. We will discuss this in Chapter 10.)

As COBIT notes, "The proposed process model is a complete, comprehensive model, but it is not the only possible process model. Each enterprise must define its own process set, taking into account its specific situation." <<ISACA2012a>>, p.32.

COBIT is strongly supportive of the standard CMMI/ISO/IEC 15504 process maturity progression and therefore is subject to the previous criticisms regarding the suitability of this approach for digital management, especially research and development processes and other less repeatable activities.

[cols="2,6", options="header"]
|====
|CObIT Domain|Process
|Evaluate, Direct and Monitor (EDM) [*Governance* processes]
|EDM01 Ensure Governance Framework Setting and Maintenance +
EDM02	Ensure Benefits Delivery +
EDM03	Ensure Risk Optimisation +
EDM04	Ensure Resource Optimisation +
EDM05	Ensure Stakeholder Transparency +
|Align, Plan and Organize (APO)
|APO01	Manage the IT Management Framework +
APO02	Manage Strategy +
APO03	Manage Entreprise Architecture +
APO04	Manage Innovation +
APO05	Manage Portfolio +
APO06	Manage Budget and Costs +
APO07	Manage Human Relations +
APO08	Manage Relationships +
APO09	Manage Service Agreements +
APO10	Manage Suppliers +
APO11	Manage Quality +
APO12	Manage Risk +
APO13	Manage Security +
|Build, Acquire and Implement (BAI)
|BAI01	Manage Programs and Projects +
BAI02	Manage Requirements Definition +
BAI03	Manage Solutions Identification and Build +
BAI04	Manage Availability and Capacity +
BAI05	Manage Organisational Change Enablement +
BAI06	Manage Changes +
BAI07	Manage Changes Acceptance and Transitioning +
BAI08	Manage Knowledge +
BAI09	Manage Assets +
BAI10	Manage Configuration +
|Deliver, Service and Support (DSS)
|DSS01	Manage Operations +
DSS02	Manage Service Requests and Incidents +
DSS03	Manage Problems +
DSS04	Manage Continuity +
DSS05	Manage Security Services +
DSS06	Manage Business Process Controls +
|Monitor, Evaluate and Assess (MEA)
|MEA01	Monitor, Evaluate and Assess Performance and Conformance +
MEA02	Monitor, Evaluate and Asses the System of Internal Control +
MEA03	Evaluate and Assess Compliance with External Requirements +
|====

Each process is further elaborated into practices. For example, the process APO08 (Manage Relationships) has the following management practices:

* APO08.01 Understand business expectations.
* APO08.02 Identify opportunities, risk and constraints for IT to enhance the business.
* APO08.03 Manage the business relationship.
* APO08.04 Co-ordinate and communicate.
* APO08.05 Provide input to the continual improvement of services.

Inputs and outputs are documented at the management practice level.

COBIT can be freely accessed through www.isaca.org.

anchor:TOGAF[TOGAF]

====== TOGAF
The Open Group Architecture Framework, is a framework and method for IT and enterprise architecture practices. TOGAF advocates an "Architecture Development Method" consisting of:

* Architecture Vision
* Business Architecture
* Information Systems Architectures
* Technology Architecture
* Opportunities and Solutions
* Migration Planning
* Implementation, Governance
* Architecture Change Management

TOGAF can be freely accessed through www.opengroup.org.

We will discuss architecture and TOGAF more in Chapter 12.

====== Other frameworks
Many other frameworks exist, under varying governance models from open to proprietary. An up to date list is maintained by Van Haren Publishing in their publication Global Standards and Publications (Van Haren Publishing, 2016). xref:Agile-frameworks[Agile frameworks] were discussed in Chapter 8. Finally, there is a broad ecosystem of vendor-specific certifications as well, to educate practitioners in the specifics of various commercial products.

===== Observations on the frameworks
ifdef::collaborator-draft[]

****
*Collaborative*

_Status: This section is in first draft as of 9 Jun 2016. Comments appreciated._

include::../../../collab-links.adoc[]

****

endif::collaborator-draft[]

In terms of the new digital delivery approaches, there are a number of issues and concerns with the xref:frameworks[frameworks]:

* The fallacy of statistical process control
* Local optimization temptation
* Lack of execution model
* Proliferation of secondary artifacts, compounded by batch orientation
* Confusion of process definition

 Add failure of risk management quote from Hubbard p 73

anchor:problem-statisical-process[]

====== The problem of statistical process control

CMM author Watts Humphrey's original vision was to apply full statistical process control to the software process. As he stated at the time:

_Dr. W. E. Deming, in his work with the Japanese after World War II, applied the concepts of statistical process control to many of their industries. While there are important differences, these concepts are just as applicable to software as they are to producing consumer goods like cameras, television sets, or auto mobiles._ (<<Humphrey1989>>, p. 3)

The overall CMM/CMMI idea (in the well-known staged model) is that a process cannot be improved and optimized until it is fully under control. Perhaps well-defined industrial processes should not be optimized until they are fully "managed." However, as we discussed in the previous section,  process control theorists see creative, knowledge-intensive processes as requiring xref:empirical-process-control[empirical control]. SPC applied to software has therefore been criticized as inappropriate <<Racynski2008>>.

In CMM terms, empirical process control starts by measuring and immediately optimizing (adjusting). To restate the Martin Fowler quote from the last section: "a process can still be controlled even if it can't be defined."<<Schwaber2002>> They need not -- and *cannot* -- be fully defined. One of the most questionable aspects of CMMI therefore, is its implication that process optimization is _something only done at the highest levels of maturity_.

*In short, the CMMI staged model encourages the thought that process improvement (optimization) only  is possible at Level 5. Many companies implementing CMMI stages however will pragmatically say "Maybe we only need to get to level 3." This implies that they define and manage their processes, but never improve them.*

This runs against much current thinking and practice, especially that deriving from Lean philosophy, in which processes are seen as always under improvement. (See discussion of xref:Toyota-Kata[Toyota Kata].) All definition, measurement, and control must serve that end.

The CMMI has evolved since Humphrey's initial vision, but between its  mis-applicaton of statistical process control, and the idea that that process optimization is only relevant at the highest maturity, it is (in the view of this author) badly out of step with current digital trends.

The other frameworks do not embrace statistical process control to the same extent as the CMMI. PMBOK suggests that "control charts may also be used to monitor cost and schedule variances, volume, and frequency of scope changes, or other management results to help determine if the project management processes are in control" (<<PMI2013>>, Kindle Locations 4108-4109). This also contradicts the insights of empirical process control, unless the project were also a fully defined process -- unlikely from a process control perspective.

====== Local optimization temptation
[quote, Eli Goldratt, The Goal]
We must not seek to optimize every resource in the system … A system of local optimums is not an optimum system at all; it is a very inefficient system.

IT capability frameworks can be harmful if they lead to fragmentation of improvement effort and lack of focus on the flow of IT value.

The digital delivery system at scale is a complex socio-technical system, including people, process, and technology. Frameworks help in understanding it, by breaking it down into component parts in various ways. This is all well and good, but the danger of *reductionism* emerges.

NOTE: There are various definitions of "reductionism." This discussion reflects one of the more basic versions.

A reductionist view implies that a system is nothing but the sum of its parts. Therefore, if each of the parts is attended to, the system will also function well.

This can lead to a compulsive desire to do "all" of a framework. If ITIL calls for 25 processes, then a large, mature organization by definition should be good at all of them. But the 25 processes (and dozens more sub-processes and activities) called for by ITIL, or the 32 called for by COBIT, are somewhat arbitrary divisions. They overlap with each other.

Furthermore, there are many digital organizations that do not use the full ITIL or COBIT process portfolio and yet deliver value as well as organizations that do use ITIL.

This temptation for local, process-level optimization runs counter to core principles of Lean and Systems Thinking. Many management thinkers, including W.E. Deming, Eli Goldratt, and others have emphasized the dangers of local optimization, and the need for taking a systems view.

As this book's structure suggests, delivering IT value requires different approaches at different scales. There is recognition of this among framework practitioners; however, the frameworks themselves provide insufficient guidance on how they scale up and down.

 Sutton observations on CMM: stipulates/strongly advocates functional specialization

anchor:lack-execution-model[]

====== Lack of execution model
It is also questionable whether even the largest actual IT organizations on the planet could fully implement the frameworks. Specifying too many interacting processes has its own complications.

Consider: Both ITIL and COBIT devote considerable time to documenting possible process inputs and outputs. As a part of every process definition, ITIL has a section entitled "Triggers, inputs, outputs, and interfaces." The Service Level Management Process (<<TSO2011b>>, pp 120-122) for example, lists:

* 7 triggers (e.g. "service breaches")
* 10 inputs (e.g. "customer feedback")
* 10 outputs (e.g. "reports on OLAs")
* 7 interfaces (e.g. "Supplier management")

COBIT similarly details process inputs and outputs. In the Enabling Processes guidance, each management practice suggests inputs and outputs. For example, the APO08 process "Manage Relationships" has an activity of "Provide input to the continual improvement of services," with

* 6 inputs
* 2 outputs

But processes do not run themselves. These process inputs and outputs require staff attention. They often imply xref:queuing[queues] and therefore Work in Process, often invisible. They impose demand on the system and each handoff represents transactional friction. Some handoffs may be implemented within the context of an IT management suite; others may require procedural standards, which themselves need to be created and maintained. The industry currently lacks understanding of how feasible such fully elaborated frameworks are, in terms of the time, effort, and organizational structure they imply.

We have discussed the issue of overburden previously. Too many organizations have contending execution models, where projects, processes, and miscellaneous work all compete for people's attention. In such environments, the overburden and wasteful xref:multi-tasking[multi-tasking] can reach crisis levels. With ITIL in particular, because it does not cover project management or architecture, we have a very large quantity of potential process interactions that is nevertheless incomplete.

anchor:secondary-artifacts[]

====== Secondary artifacts, compounded by batch orientation
[quote, Jeff Gothelf, Lean UX]
We move away from heavily documented handoffs to a process that creates only the design artifacts we need to move the team’s learning forward.

The process handoffs also imply that artifacts (documents of various sorts, models, software, etc.) are being created and transferred in between teams, or at least between roles on the same team with some degree of formality.

Primary artifacts are executable software and any additional content intended directly for value delivery. Secondary artifacts are anything else.

An examination of the ITIL and COBIT process interactions shows that many of the artifacts are secondary concepts such as "plans," "designs," or "reports:"

* Design specifications (high level and detailed)
* Operation and use plan
* Performance reports
* Action plans
* Consideration and approval

and so on. (Note that actually executable artifacts are not included here.)

Again, artifacts do not create themselves. Hundreds of artifacts are implied in the process frameworks. Every artifact implies:

* Some template or known technique for performing it
* People trained in its creation and interpretation
* Some capability to store, version, and transmit it

Unstructured artifacts such as plans, designs, and reports in particular impose high cognitive load. As digital organizations automate their pipelines, it becomes essential to identify the key events and elements they may represent, so that they can be embedded into the automation layer.

Finally, even if a given process framework does not specifically call for waterfall, one can sometimes still see its legacy. For example:

* Calls for thorough project planning and estimation
* Cautions against "cutting corners"
* "Design specifications" moving through approval pipelines (and following a progression from general to detailed)

All of these tend to signal a large batch orientation, even in frameworks making some claim of supporting Agile.

Good system design is a complex process. We introduced xref:technical-debt-1[technical debt] in Chapter 3, and will revisit it in technical-debt[Chapter 12]. But the slow xref:2.00.01-feedback[feedback] signals resulting from the batch processes implied by some frameworks are unacceptable in current industry. This is in part why new approaches are being adopted.

====== Confusion of process definition

One final issue with the "process" frameworks is that, while they use the word "process" prominently, they are not aligned with Business Process Management best practices. <<Betz2011b>>

All of these frameworks provide useful descriptions of major ongoing capabilities and functions that the large IT organization must perform. But in terms of our preceding discussion on process method, they in general are developed from the perspective of steady-state functions, as opposed to a value stream or defined process perspective.

This can be seen by looking above at ITIL, for example. A Business Process Management consultant would see the term "Capacity Management" and observe that it is not countable or event-driven. "How many Capacities did you do today?," might be the question.

The BPM community is clear that processes and countable and event-driven (see <<Sharp2009>>). Naming them with a strong active verb is seen as essential. "True" IT processes therefore might include:

* Accept Demand
* Deliver Release
* Complete Change
* Resolve Incident
* Improve Service

The lack of countability throughout the IT frameworks' conception of "process" has caused confusion and lack of alignment with BPM professionals for years, and remains an ongoing problem.

In the next chapter section, we'll consider some of these concerns further, and responses consistent with current Agile, Lean, and digital approaches.
