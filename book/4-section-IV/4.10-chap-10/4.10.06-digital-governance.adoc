
==== Digital Governance
[quote, Gorans/Ambler, Disciplined Agile Delivery]
...transforming to an agile delivery approach is difficult. Companies or government agencies that have been in existence for decades have built up layers of deep and wide waste, many of them around governance. +
 +
Business or IT governance constructs and processes that do not support new technology-centric go-to-market models and products must be either replaced or substantially evolved; otherwise, they *increase* risk on the agile projects [emphasis added].

As with other chapters, we have presented the material defining this chapter's topic "on its own terms." Certainly, there is little chance that the core principles of governance will cease to have importance, even in the new digital economy.

However, as Ambler and Gorans note above, the legacy of IT governance is wide, deep, and often wasteful. Approaches based on mis-applied xref:taylorism[Taylorism] and misguided, CMM-inspired xref:problem-statisical-process[statistical process control] have resulted in the creation of ineffective, large-scale xref:what-is-IT[IT bureaucracies] whose sole mission seems to be the creation and exchange of non-value-add xref:secondary-artifacts[secondary artifacts], while lacking any clear concept of an xref:lack-execution-model[execution model].

What is to be done? Governance will not disappear any time soon. Simply arguing against governance (ala xref:3.08.03-NoEstimates[NoEstimates]) is unlikely to succeed.

Instead, this book argues the most effective answer lies in a re-examination of the true concerns of governance:

* sustaining innovation and effective value delivery
* maintaining efficiency
* optimizing risk

These fundamental principles ("top-line," "bottom-line," "risk") define value for organizations around the world, whether for-profit, non-profit, or governmental. After considering the failings of IT governance, we'll re-examine it in light of these objectives and come up with some new answers for the digital era.

===== The failings of IT governance

From the perspective of digital transformation, there are many issues with traditional IT governance and the assumptions and practices characterizing it.

====== The fundamental lesson of digital transformation

Consider the idea of  "xref:programmability[programmability]" mentioned at the start of this chapter. A highly "programmable" position is one where the responsibilities can be specified in terms of their activities. *And what is the fundamental reality of digital transformation?* It is no accident that such positions are called "programmable." In fact, they *are* being "programmed away" or "eaten by software"- leaving only higher-skill positions that are best managed by objective, and which are more sensitive to cultural dynamics.

Preoccupation with "efficiency" fades as a result of the decreasingly "programmable" component of work. The term "efficiency" signals a process that has been well defined (is "programmable") to the point where it is repeatable and scalable. Such processes are ripe for automation, commoditization, and outsourcing, and this is in fact happening.

If the repetitive process is retained within an organization, the drive for efficiency leads to automation, and eventually efficiency is expressed through concerns for capacity management and the consumption of computing resources.

And when such repetitive concerns are *not* retained by the organization, but instead become a matter of sourcing rather than execution, the emphasis shifts to risk management and governance of the supplier.

The remaining uncertain and creative processes *should not just be managed for "efficiency"* and need to be managed for effectiveness, including fast feedback, collaboration, culture, and so forth.

====== Project versus operations as operating model

image::images/4.10-38500similar.png[]

_similar to <<ISO2008>>_

As we can see in the above diagram, ISO/IEC 38500 assumes a specific IT operating model, one in which projects are distinct from operations. We have discussed the growing influence of product-centric digital management throughout this book, but as of 2016 the major IT governance standard still does not recognize it.

The ripple effects are seen throughout other guidance and commentary. In particular, the project-centric mindset is closely aligned to the idea of IT and the CIO as primarily order-takers.

====== CIO as order-taker
Throughout much of the IT governance guidance, certain assumptions become evident:

* There is an entity that can be called "The Business."
* There is a distinct entity called "IT" (for "Information Technology").
* It is the job of "IT" to take direction (i.e. orders)  from "The Business" and to fulfill them.
* There is a significant risk that "IT" activities (and by extension, dollars spent on them) may *not* be correctly allocated to the preferred priorities of "The Business." IT may spend money unwisely, on technology for its own sake. This risk needs to be controlled.
* The needs of "The Business" can be precisely defined and it is possible for "IT" to support those needs with a high degree of predictability as to time and cost. This predictability is assumed even when those activities imply multi-million dollar investments and months or years of complex implementation activities.
* When such activities do not proceed according to initial assumptions, this is labeled an "IT failure." It is assumed that the failure could have been prevented through more competent management, "rigorous" process, or diligent governance, especially on the IT side.

There may be organizations where these are reasonable assumptions. (This book does not claim they do not exist.) But there is substantial evidence for the existence of organizations for whom these assumptions are untrue.

====== The fallacies of "rigor" and repeatability
[quote, Cem Kaner et al, Testing Computer Software]
...it takes more time than you have to prove less than you'd like.

[quote, anonymous]
Rigor? Or rigor mortis?

One of the most critical, yet poorly understood facts of software development and by extension complex digital system innovation is the impossibility of "rigor."

Software engineers are taught early that "completely" testing software is impossible <<Kaner1999>>; yet it seems that this simple fact (grounded in fundamentals of computer science and information theory) is not understood by many managers.

A corollary fallacy is that of repeatable processes, when complexity is involved. We may be able to understand repeatability at a higher level, through approaches like xref:case-mgmt[case management] or the Checklist Manifesto's xref:submittal-schedule[submittal schedules], but process control in a formal sense is simply xref:empirical-process-control[impossible], and the quest for it is essentially xref:cargo-cult[cargo cult]
 management.

And yet quotes like the following are common in IT governance discussions:

_...the questions a senior manager should ask include: "How good are my IT governance processes at effectively delivering strategic business value year after year?" and "Are my processes repeatable, predictable, and scalable, and are they truly meeting the needs of my business (outside of IT) and my customers?"_ <<Moeller2008>>, p. 6.

With all due respect to the author, value that can be delivered "repeatably," "year after year" is for the most part commodity production, not innovative xref:2.04.04-lean-product-dev[product development]. Strategy is notably difficult to commoditize...

Another way to view this is in terms of the xref:trad-IT-decline[decline of traditional IT]. As you review those diagrams, understand that much of IT governance has emerged from the arguably futile effort to deliver product innovation in a low-risk, "efficient" manner. This desire has led, as Ambler and Gorans note at the top of this chapter section, to the creation of layers and layers of bureaucracy and xref:secondary-artifacts[secondary artifacts].

The cynical term for this is "theater," as in an act that is essential unreal, but presented for the entertainment and distraction of an audience.

As we noted above, a central reality of digital transformation is that commoditized, predictable, programmable, repeatable, "efficient" activities are being quickly automated, leaving governance to focus more on effectiveness of innovation (e.g. product development) and management of supplier risk. Elaborate IT operating models specifying hundreds of  interactions and deliverables, in a futile quest for "rigor" and "predictability," are increasingly relics of another time.

===== Digital effectiveness

Let's return to the first value objective: effectiveness.

We define effectiveness as "top-line" benefits: new revenues and preserved revenues. New revenues may come from product innovation, as well as successful marketing and sales of existing products to new markets (which itself is a form of innovation).

Traditionally, "back-office" information technology was rarely seen as something contributing to effectiveness, innovation, and top-line revenue. Instead, the first computers were used to increase xref:taylorism[*efficiency*], through automating clerical work. The same processes and objectives could be executed for less money, but they were still the same back-office processes.

With digital transformation, product innovation and effectiveness is now a much more important driver. Yet product-centric management is still poorly addressed by traditional IT governance, with its emphasis on distinguishing projects from operations.

One tool that becomes increasingly important is a portfolio view. While project management offices may use a concept of "portfolio" to describe temporary initiatives, such project portfolios rarely extend to tracking ongoing operational benefits. Alternative approaches also should be considered such as the idea of an  xref:options-portfolio[options approach].


===== Digital efficiency

Efficiency is a specific, technical term, and although often inappropriately prioritized, is always an important concern. Even a digitally-transforming, product-centric organization can still have governance objectives of optimizing efficiency. Here are some thoughts on how to re-interpret the concept of efficiency.

====== Consolidate the pipelines

One way in which digital organizations can become more efficient is to consolidate development as much as possible into common pipelines. Traditionally, application teams have owned their own development and deployment pipelines, at the cost of great, non-value add variability. Even centralizing source control has been difficult.

This is challenging for organizations with large legacy environments, but full-lifecycle pipeline automation is becoming well understood across various environments (including the mainframe).

====== Reduce internal service friction

Another way of increasing efficiency is to standardize integration protocols across internal services, ala xref:amazon-productization[Amazon]. This reduces the need for detailed analysis of system interaction approaches every time two systems need to exchange data. This is a form of reducing transaction costs and therefore consistent with Coase's theory of the firm <<Coase1937>>..

Within the boundary of a firm, collaboration between internal services should be easier because of reduced transaction costs. It's not hard to see that this would be the case for digital organizations: security, accounting, customer relationship management would all be more challenging and expensive for externally-facing services.

However, since a firm is a system, a service within the boundaries of a firm will have more constraints than a service constrained only by the market. The internal service may be essential to other, larger-scoped services, and may derive its identity primarily from that context.

Because the need for the service is well-understood, the engineering risk associated with the service may also be reduced. It may be more of a component than a product. See the parable of the xref:flower-and-cog[the Flower and the Cog]. Reducing service redundancy is a key efficiency goal within the bounds of a system -- more to come on this in Chapter 12.

====== Manage the process portfolio

Processes require ongoing scrutiny. The term "organizational scar tissue" is used when specific situations result in new processes and policies, that in turn increase transactional friction and reduce efficiency throughout the organization.

Processes can be consolidated, especially if specific procedural detail can be removed in favor of larger-grained xref:case-mgmt[case management] or xref:checklist-manifesto[Checklist Manifesto]
concepts including the xref:submittal-schedule[submittal schedule]. As part of eventual automation and digital transformation, processes can be ranked as to how "heavyweight" they are. A typical hierarchy, from "heaviest" to "lightest," might be:

* Project
* Release
* Change
* Service request
* Automated self-service

The organization might ask itself:

* Do we need to manage this as a project? Why not just a release?
* Do we need to manage this as a release? Why not just a change?
* Do we need to manage this as a change? Why not just a service request?
* Do we need to manage this as a service request? Why is it not fully automated self-service?

As we saw in our examination of the xref:google-chubby[Chubby locking service], there may be good reason to retain some formality. The point is to keep asking the question. Do we *really* need a separate process? Or can the objectives be achieved as part of an existing process or other enabler?

====== Governance as demand
A steam engine's governor imposes some load, some resistance, on the engine. In the same way, governance activities and objectives, unless fully executed by the directing body (e.g. the board), themselves impose demand on the organization.

This points to the importance of having a clear xref:demand-supply-execute[demand/execution framework] in place to manage governance demand. The organization does not have an unlimited capacity for audit response, reporting, and the like. In order to understand the organization as a system, governance demand needs to be tracked and accounted for, and challenged for efficiency just as any other sort of demand.

====== Leveraging the digital pipeline

Finally, efficiency asks: can we leverage the digital pipeline itself to achieve governance objectives? This is not a new idea. The governance/management interface must be realized va specific enablers, such as processes. Processes can (and often should) be automated. Automation is the raison d'etre of the digital pipeline; if the process can be expressed as user stories, behavior-driven design, or other forms of requirement, it simply is one more state change moving from dev to ops.

In some cases, the governance stories must be applied to the pipeline itself. This is perhaps more challenging, but there is no reason the pipeline itself cannot be represented as code and managed using the same techniques.

The automated enablers then can report their status up to the Monitoring activity of governance, closing the loop. Auditors should periodically re-assess their effectiveness.

===== Digital risk management
[quote, COBIT 5 for Risk]
Poorly governed and managed information and technology will destroy value or fail to deliver benefits...

Finally, from an IT governance perspective, what is the role of IT risk management in the new digital world? It's not that risk management goes away. Many risks that are well understood today, will remain risks for the foreseeable future. But there are significant new classes of risk that need to be better understood and managed:

* Unmanaged demand and disorganized execution models leading to multi-tasking, which is destructive of value and results
* High queue wait states, resulting in uncompetitive speed to deliver value
* Slow feedback due to large batch sizes, reducing effectiveness of product discovery
* New forms of supplier risk, as services become complex composites spanning the Internet ecosystem.
* Toxic cultural dynamics destructive of high team performance
* Failure to incorporate cost of delay in resource allocation and work prioritization decisions

All of these conditions can reduce or destroy revenues, erode organizational effectiveness, and worse. It is hard to see them as other than risks, yet there is little attention to such factors in the current (as of late 2016) "best practice" guidance on risk.

====== Cost of delay as risk

In today's digital governance there must be a greater concern for outcome and effectiveness, especially in terms of time to market (minimizing xref:cost-of-delay[Cost of Delay]). Previously, concerns for efficiency might lead a company to overburden its staff, resulting in queuing gridlock, too much work in process, destructive multitasking, and ultimately failure to deliver timely results (or deliver at all).

Such failure to deliver was tolerated because it seemed to be a common problem across most IT departments, and because digital transformation had not taken hold yet. IT systems were often back office and delays in delivering them (or significant issues in their operation) were not *quite* as damaging.

Now, effectiveness of delivery is essential. The interesting, and to some degree unexpected result, is that both efficiency and risk seem to be benefiting as well. Cross-functional, focused teams are both more effective and more efficient, and able to manage risk better as well. Systems are being built with both increased rapidity as well as improved stability, and the automation enabling this provides robust audit support.

====== Team dynamics as risk

We've covered culture in some depth in Chapter 7. Briefly, from a governance perspective:

The importance of organizational culture has been dsiscussed by management thinkers since at least W.E. Deming. In the words of ____, "culture eats strategy for breakfast." But it has been difficult at best to quantify what we mean by culture.

 find quote

Quantify? Some might even say quantification is impossible. But Google and the State of DevOps research have done so. Google has established the importance of psychological safety in forming effective, high-performing teams <<Rozovsky2015>>. And the State of DevOps research, applying the Westrum typology, has similarly confirmed that pathological, controlling cultures are destructive of digital value <<Puppet2015>>.

These facts should be taken seriously in digital governance discussions. So-called "command and control" management (which in the military itself can be deemed "toxic") is destructive of organizational goals and stakeholder value. It can be measured and managed, and should be a matter of attention at the highest levels of organizational governance.

 toxic leadership cite from military source

====== Sourcing and SIAM risk

We've touched on the issues of xref:cloud-due-diligence[Cloud due diligence] and xref:sourcing-and-security[sourcing and security] in this chapter, and xref:SIAM[supplier integration and management] in chapter 8. The 2e2 case discussed is interesting; it seems that due diligence had actually been performed. Additional controls could have made a key difference, in particular xref:business-continuity[business continuity planning].

There are a wide variety of supplier-side risks that must be managed in Cloud contracts:

* Access
* Compliance
* Data location
* Multi-tenancy
* Recovery
* Investigation
* Viability (assurance)
* Escrow

 The leading edge of Cloud sourcing is represented in discussions such as  "Dynamic certification of Cloud services: Trust, but verify!" Lins et al, computing edge (advanced).

We have already covered contracting in terms of software and Cloud. But in terms of the emergence model, it is typical that companies enter into contracts before having a fully mature sourcing and contract management capability with input from the governance, risk, and compliance perspective.

Risk management in a full SIAM (Supplier Integration and Management) sense is compounded by the complex interdependencies of the services involved. All of the Cloud contracting risks need to be covered, as well as further questions such as:

* If a given service depends on two sub-services ("underpinning contracts"), what are the risks for the failure of either or both of the underpinning services? What are the controls?

===== Automating digital governance

====== Digital exhaust

One governance principle we will suggest here is to develop a governance architecture as an inherent part of the delivery system, not as an additional set of activities. We use the concept of "digital exhaust" to reinforce this.

****
*What is "digital exhaust"?*

Digital exhaust consists of the extraneous data, and information that can be gleaned from it, originating from the development and delivery of IT services.

Consider an automobile's exhaust. It does not help you get to where you are going, but it's an inevitable aspect of having an internal combustion engine. Since you have it, you can monitor it and gain certain insights as to whether your engine is running efficiently and effectively. You might even be able to identify if you are at risk of an engine failure.

****

To leverage digital exhaust, focus on the critical, always-present systems that enable digital delivery:

* In chapter 2, we introduced the concept of xref:version-control[version control]
* In chapter 3 we introduced the idea of a xref:continuous-delivery[continuous delivery pipeline]
* In chapter 6 we introduced xref:monitoring[monitoring] as part of operations

These systems constitute a core digital pipeline, one that can be viewed as an engine producing digital exhaust.

This is in contrast to fragmented, poorly-automated pipelines, or organizations with little concept of pipeline at all. Such organizations wind up relying on xref:secondary-artifacts[secondary artifacts]
 and manual processes to deliver digital value:

image::images/4.10-gov-2ndary.png[]

The above diagram represents fragmented delivery pipelines, with many manual processes and secondary artifacts (waterfall stage approvals, designs, plans, manual ticketing, and so forth). Much IT governance assumes this model, and also assumes that governance must often rely on aggregating and monitoring the secondary artifacts.

With a rationalized continuous delivery pipeline, governance increasingly can focus on monitoring the digital exhaust:

image::images/4.10-gov-exhaust.png[]

What can we monitor with digital exhaust for the purposes of governance?

* Development team progress against backlog
* Configuration management
* Conformance to architectural standards (through inspection of source and package managers, code static analysis, and other techniques)
* Complexity and technical debt
* Performance and resource consumption of services
* Performance of standards against automated hardening activities (e.g. xref:simian-army[Simian Army])

As noted above, certain governance objectives may require the pipeline itself to be adapted, e.g. the addition of static code analysis, or implementation of hardening tools such as Simian Army.

====== Additional automation

****
*The DevOps Audit Toolkit*

The DevOps Audit Toolkit provides an audit perspective on pipeline automation <<DeLuccia2015>>. This report provides an important set of examples demonstrating how modern DevOps toolchain automation can fulfill audit objectives as well or better than "traditional" approaches. This includes a discussion of alternate approaches to the traditional control of "separation of duties" for building and deploying code. These approaches include automated code analysis and peer review as a required control.
****

There are a variety of ways the IT pipeline can be automated. The Calavera simulation <<Betz2015>> shows a simplified end to end approach. Many additional components are seen in real-world pipelines:

* Static code analyzers
* Automated user interface (UI) testing
* Load testing
* More sophisticated continuous deployment infrastructure

and much more.

Additionally, there may still be a need for systems that are secondary to the core pipeline.

* Service or product portfolio
* Workflow and kanban-based systems (one notable example is workflow to ensure peer review of code)
* Document management

There may also be a risk repository, if the case can't be made to track risks using some other system. The important thing to remember when automating risk management is that risks are always with respect to some *thing*.

A risk repository needs to be integrated with subject inventories, such as the service portfolio and relevant source repositories and entries in the package manager. Otherwise, risk management will remain an inefficient, highly manual process.

What are the things that may present risks?

* Products/services
** Their ongoing delivery
** Their changes & transformations (Releases)
** Their revenues

* Customers and their data
* Employees and their positions
* Assets
* Vendors
* Other critical information

anchor:simian-army[]

====== The Netflix Simian Army
[quote, Izrailevsky & Tseitlin, Netflix Tech Blog]
...just designing a fault tolerant architecture is not enough. We have to constantly test our ability to actually survive these "once in a blue moon" failures. +
 +
Imagine getting a flat tire. Even if you have a spare tire in your trunk, do you know if it is inflated? Do you have the tools to change it? And, most importantly, do you remember how to do it right? One way to make sure you can deal with a flat tire on the freeway, in the rain, in the middle of the night is to poke a hole in your tire once a week in your driveway on a Sunday afternoon and go through the drill of replacing it. This is expensive and time-consuming in the real world, but can be (almost) free and automated in the cloud. +
 +
This was our philosophy when we built Chaos Monkey, a tool that randomly disables our production instances to make sure we can survive this common type of failure without any customer impact. The name comes from the idea of unleashing a wild monkey with a weapon in your data center (or cloud region) to randomly shoot down instances and chew through cables -- all the while we continue serving our customers without interruption. By running Chaos Monkey in the middle of a business day, in a carefully monitored environment with engineers standing by to address any problems, we can still learn the lessons about the weaknesses of our system, and build automatic recovery mechanisms to deal with them.

The Netflix Simian Army is a collection of resiliency tools developed by the online video-streaming service Netflix. It represents a significant advancement in digital risk management, as previous control approaches too often were limited by poor scalability or human failure (e.g. forgetfulness or negligence in following manual process steps).

Chaos Monkey is one of a number of tools developed to continually "harden" the Netflix system, including:

* Latency Monkey -- introduces arbitrary network delays
* Conformity Monkey -- checks for consistency with architectural standards, and shuts down non-conforming instances
* Doctor Monkey -- checks for longer-term evidence of instance degradation
* Janitor Monkey -- checks for and destroys unused running capacity
* Security Monkey -- an extension of Conformity Monkey, checks for correct security configuration
* 10-18 Monkey -- checks internationalization
* Finally, Chaos Gorilla simulates the outage of an entire Amazon availability zone

On the whole, the Simian Army behaves much as antibodies do in an organic system. One notable characteristic is that the monkeys as described do not generate a report (a xref:secondary-artifacts[secondary artifact]) for manual followup. They simply shut down the offending resources.

Such direct action may not be possible in many environments, but represents an ideal to work toward. It keeps the security and risk work "front and center" within the mainstream of the digital pipeline, rather than relegating it to the bothersome "additional work" it can so easily be seen as.
