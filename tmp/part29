\subsection{Infrastructure as code}
\label{_infrastructure_as_code}\hyperlabel{_infrastructure_as_code}%
  \begin{quote}

Infrastructure as code is an approach to infrastructure automation based on practices from software development. It emphasizes consistent, repeatable routines for provisioning and changing systems and their configuration. Changes are made to definitions and then rolled out to systems through unattended processes that include thorough validation. The premise is that modern tooling can treat infrastructure as if it were software and data. This allows people to apply software development tools such as version control systems (VCS), automated testing libraries, and deployment orchestration to manage infrastructure. It also opens the door to exploit development practices such as test-{}driven development (TDD), continuous integration (CI), and continuous delivery (CD).

\hspace*\fill--- Kief Morris
\emph{Infrastructure as Code: Managing Servers in the Cloud} \end{quote}
 
So, what is infrastructure as code?
 
As cloud infrastructures have scaled, there has been an increasing need to configure many servers identically. Auto-{}scaling (adding more servers in response to increasing load) has become a widely used strategy as well. Both call for increased automation in the provisioning of IT infrastructure. It is simply not possible for a human being to be hands on at all times in configuring and enabling such infrastructures, so automation is called for.
 
In years past, infrastructure administrators relied on ad-{}hoc issuance of commands either at an operations console, or via a GUI-{}based application. Shell scripts might be used for various repetitive processes, but administrators by tradition and culture were empowered to issue arbitrary commands to alter the state of the running system directly.
 
The following passage from The Phoenix Project captures some of the issues. The speaker is Wes, the infrastructure manager, who is discussing a troubleshooting scenario:
 
\emph{\textquotedblleft{}Several months ago, we were three hours into a Sev 1 outage, and we bent over backward not to escalate to Brent. But eventually, we got to a point where we were just out of ideas, and we were starting to make things worse. So, we put Brent on the problem.\textquotedblright{} He shakes his head, recalling the memory, \textquotedblleft{}He sat down at the keyboard, and it's like he went into this trance. Ten minutes later, the problem is fixed. Everyone is happy and relieved that the system came back up. But then someone asked, `How did you do it?' And I swear to God, Brent just looked back at him blankly and said, `I have no idea. I just did it.'\textquotedblright{}}
 
\hyperlink{Kim2013}{[Kim2013]}, p. 116.
 
Obviously, \textquotedblleft{}close your eyes and go into a trance\textquotedblright{} is not a repeatable process. It is not a procedure or operation that can be archived and distributed across multiple servers. So, shell scripts or more advanced forms of automation are written and increasingly, all actual server configuration is based on such pre-{}developed specification. It is becoming more and more rare for a systems administrator to actually \textquotedblleft{}log in\textquotedblright{} to a server and execute configuration-{}changing commands in an ad-{}hoc manner (as Brent).
 
In fact, because virtualization is becoming so powerful, servers increasingly are destroyed and rebuilt at the first sign of any trouble. In this way, it is certain that the server's configuration is as intended. This again is a relatively new practice.
 
Previously, because of the expense and complexity of bare-{}metal servers, and the cost of having them offline, great pains were taken to fix troubled servers. Systems administrators would spend hours or days troubleshooting obscure configuration problems, such as residual settings left by removed software. Certain servers might start to develop \textquotedblleft{}personalities.\textquotedblright{} Industry practice has changed dramatically here since around 2010.
 
\label{infra-code-example}\hyperlabel{infra-code-example}
 
\subsubsection{A simple infrastructure as code example}
\label{_a_simple_infrastructure_as_code_example}\hyperlabel{_a_simple_infrastructure_as_code_example}%
  
\textbf{Note, the below Part Is illustrative only, and is not intended as a lab. The associated lab for this book goes into depth on these topics.}
 
In presenting infrastructure as code at its simplest, we will start with the concept of a shell script. While this is not a deep Linux book (there are many others out there, starting with the excellent O'Reilly lineup), some basic technical literacy is assumed in this book. Consider the following set of commands:
 
\begin{lstlisting}[firstnumber=1,backgroundcolor={},basicstyle=\ttfamily,]
$ mkdir foo bar
$ cd foo
$ touch x y z
$ cd ../bar
$ touch a b c
\end{lstlisting}
 
What does this do? It tells the computer:
 \begin{enumerate}[label=\arabic*.]

\item{} Create (\texttt{mkdir}) two directories, one named foo and one named bar.
 

\item{} Move (\texttt{cd}) to the one named foo
 

\item{} Create (\texttt{touch}) three files, named x, y, and z
 

\item{} Move to the directory named bar
 

\item{} Create three blank files, named a, b, and c.
 
\end{enumerate}
 
If you find yourself (with the appropriate permissions) at a Unix command prompt, and run those commands, you will wind up with a configuration that could be visualized as this:
 \begin{wrapfigure}{r}{0.5\textwidth}

\begin{center}
\imgexists{images/1_02-iac.png}{{\imgevalsize{images/1_02-iac.png}{\includegraphics[width=0.48\textwidth]{images/1_02-iac.png}}}}{folders/files}
\end{center}
\caption{Simple directory/file structure}
\end{wrapfigure}
 
(If you don't understand this, you should probably spend a couple hours with a Linux tutorial).
 
Configuration, you ask? Something this trivial? Yes, directory and file layouts count as configuration and in some cases are critical. Now, what if we take that same set of commands, and put them in a file thus:
 
\begin{lstlisting}[firstnumber=1,backgroundcolor={},basicstyle=\ttfamily,]
#!/bin/bash
mkdir foo bar
cd foo
touch x y z
cd ../bar
touch a b c
\end{lstlisting}
 
We might name that file \texttt{iac.\penalty0 sh}, set its permissions correctly, and run it (so that the computer executes all the commands for us, rather than us running them one at a time at the console).  If we did so in an empty directory, we'd again wind up with that same configuration. (If we did it in a directory already containing foo and bar directories, we'd get errors. More on this to come.)
 \begin{DBKadmonition}{}{Note}
 
The state of the art in infrastructure configuration is not to use shell scripts at all but rather policy-{}based infrastructure management approaches, which we discuss subsequently.
 \end{DBKadmonition}
 
This will be familiar material to many of you, including the fact that beyond creating directories and files we can use shell scripts to create and destroy virtual servers, install and remove software, set up and delete users, check on the status of running processes, and much more.
 
Sophisticated infrastructure as code techniques are are essential part of modern site reliability engineering practices such as used by Google. Auto-{}scaling, self-{}healing systems, fast deployments of new features all require that infrastructure be represented as code for maximum speed and reliability of creation.
 
Let's return to our iac.sh file. It's valuable. It documents our intentions for how this configuration should look. We can reliably run it on thousands of machines and it will always give us two directories and six files. In terms of the previous section, we might choose to run it on every new server we create. We want to establish it as a known resource in our technical ecosystem. This is where version control and the broader concept of configuration management come in.
 

\begin{sidebar}
\textbf{Cattle not pets?}


In earlier times, servers (that is, computers managed on a distributed network) were usually configured without virtualization. They arrived (carefully packed on pallets) from the manufacturer unconfigured, and would be painstakingly "built" by the systems administrator: the operating system would be compiled and installed, key software packages (such as Java) installed, and then the organization's customer software installed.

At best, the systems administrators, or server engineers, might have written guidelines or perhaps some shell scripts that would be run on the server to configure it in a semi-{}consistent way. But that documentation would often be out of date, the scripts would be unique to a given administrator, and there would be great reluctance to "rebuild the box" -{} that is, to delete everything on it and do a "clean re-{}install." Instead, if there were problems, the administrator would try to fix the server by going in and adjusting particular settings (typically by changing configuration files and restarting services), or deleting software packages and re-{}installing them.

The problem with this is that modern computing systems are so complex that deleting software can be difficult; if the un-{}install process fails in some way, the server can be left in a compromised state. Similarly, one-{}time configuration adjustments made to one server means that it may be inconsistent with similar devices, and this can cause problems. For example, if the first systems administrator is on vacation, their substitute may expect the server to be configured in a certain way and make adjustments that have unexpected effects. Or the first systems administrator themselves may forget exactly what it is they did. Through such practices, servers would start to develop personalities, because their configurations were inconsistent.

As people started to work more and more with virtualization, they realized it was easier to rebuild virtual servers from scratch, rather than trying to fix them. Automated configuration management tools helped by promoting a consistent process for rebuilding. Randy Bias, noting this, put forth the provocative idea that "servers are cattle, not pets" \hyperlink{Bias2012}{[Bias2012]}. That is, when a pet is sick, one takes it to the vet, but a sick cow might simply  be taken out and shot.

I prefer the saying that "servers are fleet vehicles, not collectible cars" as it seems less cruel, and the cattle metaphor overlooks the fact that large animal veterinarians are routinely employed in the cattle industry.
\begin{wrapfigure}{r}{0.5\textwidth}

\begin{center}
\imgexists{images/1_02-vehicles.png}{{\imgevalsize{images/1_02-vehicles.png}{\includegraphics[width=0.48\textwidth]{images/1_02-vehicles.png}}}}{collectible car}
\end{center}
\caption[{Collectible car versus fleet vehicles }]{Collectible car versus fleet vehicles \footnotemark{}}
\end{wrapfigure}
\end{sidebar}
 
For further information and practical examples, see \emph{Infrastructure as Code} by Kief Morris \hyperlink{Morris2016}{[Morris2016]}.
 
\label{version-control}\hyperlabel{version-control}
   
